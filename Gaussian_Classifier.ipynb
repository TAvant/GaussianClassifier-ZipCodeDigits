{
 "metadata": {
  "name": "",
  "signature": "sha256:b36180768741313be69649014d85675279024fa5fbc85f2b97ffcc81a05287bb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Gaussian Classifier</h1>\n",
      "<h3>Overview</h3>\n",
      "<p>The goal of this notebook is to create a gaussian classifier that takes in images of handwritten zip code digits and predict their corresponding labels, in this case a digit between zero and nine. First, a set of training data will be divided into ten subsets based on their corresponding label. Each subset of data will be used to obtain a probability density function (pdf). Once the pdf\u2019s have been obtained, the training data can be disregarded. To classify a given image from a test set, the image data is computed on each of the ten pdf\u2019s. The predicted label assigned to the test data is that of the pdf which returns the largest probability. The predicted labels are then compared with the actual labels of the test set. This is accomplished using a confusion matrix, in which the rows are the actual labels and the columns are the predicted labels. The values in each of the cells are the proportion of labels correctly or incorrectly predicted. Ideally, the result of the confusion matrix would be the identity matrix.</p>\n",
      "<h3>Zip Code Data</h3>\n",
      "<p>The zip code data for this notebook can be found at the website of \"<a href=http://statweb.stanford.edu/~tibs/ElemStatLearn/>The Elements of \n",
      "Statistical Learning</a>\" (ESL). The data consists of 7291 training observation and 2007 test observation. Each observation is 16 x 16 grayscale image of a handwritten zip code digit, ranging from zero to nine.</p>\n",
      "<table width=\"100%\">\n",
      "    <tr bgcolor=\"AliceBlue\">\n",
      "        <td></td>\n",
      "        <td>Zero</td>\n",
      "        <td>One</td>\n",
      "        <td>Two</td>\n",
      "        <td>Three</td>\n",
      "        <td>Four</td>\n",
      "        <td>Five</td>\n",
      "        <td>Six</td>\n",
      "        <td>Seven</td>\n",
      "        <td>Eight</td>\n",
      "        <td>Nine</td>\n",
      "        <td>Total Observations</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "        <td bgcolor=\"AliceBlue\">Training Data</td>\n",
      "        <td>1194</td>\n",
      "        <td>1005</td>\n",
      "        <td>731</td>\n",
      "        <td>658</td>\n",
      "        <td>652</td>\n",
      "        <td>556</td>\n",
      "        <td>664</td>\n",
      "        <td>645</td>\n",
      "        <td>542</td>\n",
      "        <td>644</td>\n",
      "        <td>7291</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "        <td bgcolor=\"AliceBlue\">Test Data</td>\n",
      "        <td>359</td>\n",
      "        <td>264</td>\n",
      "        <td>198</td>\n",
      "        <td>166</td>\n",
      "        <td>200</td>\n",
      "        <td>160</td>\n",
      "        <td>170</td>\n",
      "        <td>147</td>\n",
      "        <td>166</td>\n",
      "        <td>177</td>\n",
      "        <td>2007</td>\n",
      "    </tr>\n",
      "</table>\n",
      "<h3>Building the Classifier</h3>\n",
      "<p>When building the gaussian classifier, the following steps were preformed for each class (label) of the training data.</p>\n",
      "<ol>\n",
      "    <li>Compute the mean $$\\mu=\\frac{1}{N}\\sum^{N}x_{i}$$</li>\n",
      "    <li>Compute the covariance (sigma) \n",
      "    $$\\mathbf{\\Sigma}=\\frac{1}{N}\\sum^{N}\\left(x_{i}-\\mu\\right)\\left(x_{i}-\\mu\\right)^{T}$$</li>\n",
      "    <li>Fit a multivariate normal distribution (gaussian) $$\\frac{1}{(2\\pi)^{\\frac{k}{2}}|\\mathbf{\\Sigma}|^{-\\frac{1}{2}}}e^{ -\\frac{1}{2}(x-\\mu)^{T}\\mathbf{\\Sigma}^{-1}(x-\\mu)}$$</li>\n",
      "</ol>\n",
      "<p>It is possiable that the determinante of sigma, $|\\mathbf{\\Sigma}|$, is zero, creating a divide by zero error and getting the inverse of sigma not possible, $\\mathbf{\\Sigma}^{-1}$. In such cases, regularization is used: $(\\mathbf{\\Sigma}+rI)$. Once fitting a gaussian to each class has been completed, each observation of the test data is classified and a confusion matrix is used to present the results.</p>\n",
      "<h3>Python Code</h3>\n",
      "<h6>Imported Libraries</h6>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import gzip\n",
      "import numpy as np\n",
      "from sets import Set\n",
      "from numpy.linalg import inv\n",
      "from numpy.linalg import det"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h6>Defined Functions</h6>\n",
      "<p></p>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p>get_mean: takes a matrix of data values and returns a vector of mean values. Each indicie of the vector is the mean value of the corresponding features of the matrix.</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mean(data):\n",
      "    # caculate mean of observations for label x\n",
      "    return np.mean(data, axis=0)[:,np.newaxis]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p>get_sigma: takes a matrix of data values and returns the covariance matrix. If the determinant of the covariance matrix is singular, regularzation is used: sigma += rI. The coefficient r is by default set to 0.1.</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sigma(data, r=0.1):\n",
      "    # caculate the covariance of observations for label x\n",
      "    sigma = np.cov(data.T)\n",
      "    \n",
      "    # if sigma is not invertable (singular) use regularization \n",
      "    if abs(det(sigma)) <= 1E-9: \n",
      "        return (sigma + r*np.identity(sigma.shape[0]))\n",
      "    \n",
      "    # else return covariance\n",
      "    return sigma"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p>gaussian_distribution: takes the mean, covariance and dimensionality of a class. It returns a lambda function that is the multivariate normal distribution.</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gaussian_distribution(mean, sigma, dimension):\n",
      "    # return multivariate normal distribution (gaussian) for label x\n",
      "    const = 1.0 / (((2*pi)**(dimension/2)) * np.sqrt(det(sigma)))\n",
      "    return lambda x: const * exp(-0.5 * np.dot(np.dot((x[:,np.newaxis]-mean).T, inv(sigma)), (x[:,np.newaxis]-mean)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p>gaussian_distributions: takes the training data and labels. It seperates the training data by class (label) and returns a dict of gaussian distributions {key=label : value=gaussian_func}</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gaussian_distributions(train_data, labels):\n",
      "    # gaussian distributions for each label\n",
      "    distributions = {}\n",
      "    for label in labels:\n",
      "\n",
      "        # get training data for label x and remove col with label\n",
      "        label_data = train_data[train_data[:,0] == label][:,1:]\n",
      "\n",
      "        # get gaussian function for current label\n",
      "        distributions[label] = gaussian_distribution(mean(label_data), sigma(label_data), label_data.shape[1])\n",
      "        \n",
      "    # return gaussian distrabutions\n",
      "    return distributions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p>gaussian_classifier: takes a dict of gaussian distributions, the test data and labels. Function takes each observation, finds the probability, then adds the label with the max probability to a list. It returns an array of predicted labels.</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gaussian_classifier(gaussian_distributions, test_data, labels):\n",
      "    # caculate the probability for every observation ...\n",
      "    predicted_labels = []\n",
      "    for observation in range(test_data.shape[0]):\n",
      "        \n",
      "        # ... on each gausian distrabution\n",
      "        probabilities = []\n",
      "        for label in sorted(gaussian_distributions.keys()):\n",
      "            \n",
      "            # keep the probability for each gaussian function\n",
      "            probabilities.append(gaussian_distributions[label](test_data[observation,1:]))\n",
      "            \n",
      "        # add the label with the max probability \n",
      "        predicted_labels.append(labels[probabilities.index(max(probabilities))])\n",
      "    \n",
      "    # return a numpy array of the predicted labels\n",
      "    return np.array(predicted_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p>confusion_matrix: takes an array of actual labels, an array of predicted labels, and the class labels. It returns a matrix of proportions of correctly and incorrectly labeled predictions.</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def confusion_matrix(actual, predicted, labels):\n",
      "    # get number of class labels and observations\n",
      "    num_labels = len(Set(actual))\n",
      "    num_observations = actual.shape[0]\n",
      "    \n",
      "    # initialize a matrix of zeros\n",
      "    matrix = np.zeros((num_labels,num_labels))\n",
      "    \n",
      "    # increment cell coresponding to actual (row) and predicted (col)\n",
      "    for observation_n in range(num_observations):\n",
      "        row = labels.index(actual[observation_n])\n",
      "        col = labels.index(predicted[observation_n])\n",
      "        matrix[row, col] += 1\n",
      "    \n",
      "    # array indicies corespond with the number of class oberservations\n",
      "    class_label_sums = []\n",
      "    for label in labels:\n",
      "        class_labels = actual[actual[:] == label]\n",
      "        class_label_sums.append(class_labels.shape[0])\n",
      "    \n",
      "    # return confusion matrix proportions\n",
      "    return np.divide(matrix, np.array(class_label_sums)[np.newaxis,:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h6>Execute Gaussian Classifier</h6>\n",
      "<p></p>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p>Get the zip code training and testing data from the files.</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with gzip.open('zip.train.gz') as f:\n",
      "    train_data = np.loadtxt(f)\n",
      "    \n",
      "with gzip.open('zip.test.gz') as f:\n",
      "    test_data = np.loadtxt(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p>Get a list of the classes and sort them.</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class_labels = sorted(list(Set(train_data[:,0])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p>Get the gaussian distrabutions for each class.</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distributions = gaussian_distributions(train_data, class_labels) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p>Predicted labels of the zip code test data.</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predicted_labels = gaussian_classifier(distributions, test_data, class_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p>Get the actual labels of the test data.</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "actual_labels = test_data[:,0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p>Compare actual labels with predicted labels using a confusion matrix and display the results.</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "confusion_matrix = confusion_matrix(actual_labels, predicted_labels, class_labels)\n",
      "print confusion_matrix.round(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.98  0.    0.03  0.    0.01  0.    0.    0.    0.01  0.  ]\n",
        " [ 0.    0.97  0.    0.    0.02  0.01  0.03  0.    0.    0.  ]\n",
        " [ 0.01  0.    0.91  0.01  0.02  0.01  0.    0.01  0.03  0.  ]\n",
        " [ 0.    0.    0.02  0.89  0.    0.06  0.    0.    0.03  0.  ]\n",
        " [ 0.    0.    0.03  0.    0.92  0.    0.    0.01  0.    0.05]\n",
        " [ 0.01  0.    0.    0.02  0.    0.92  0.    0.    0.02  0.01]\n",
        " [ 0.    0.    0.01  0.    0.01  0.02  0.95  0.    0.01  0.  ]\n",
        " [ 0.    0.    0.01  0.    0.02  0.    0.    0.94  0.01  0.02]\n",
        " [ 0.01  0.    0.02  0.02  0.    0.02  0.    0.    0.9   0.01]\n",
        " [ 0.    0.    0.    0.    0.    0.    0.    0.01  0.02  0.97]]\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Thoughts</h3>\n",
      "<p>On ESL's website, they note that an accuracy 97.5% and greater is good. This gaussian classifier is obtaining that goal for the zero class and is close for the one and nine classes; however, it misses the mark on classes two through eight. Dimensionality reduction may help improve the accuracy rate of this data set.  </p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    }
   ],
   "metadata": {}
  }
 ]
}